\clearpage
\appendix
# (APPENDIX) Appendix {-}

# Original statements and used translation {#translate}

```{r atop-translation-kids, message=FALSE, warning=FALSE, include=TRUE,  echo = FALSE}
#####----------------APPENDIX: visualized the translations-----------------#####
atop_key_groups <- atop_key %>%
  arrange(question_group) %>%
  mutate(row_number = row_number()) %>%
  group_by(question_group) %>%
  summarize(first = min(row_number),
            last = max(row_number)) %>% as.data.frame()
tbl <- atop_key %>%
  dplyr::select(question_text_english, question_text_french,
                question_text_dutch) %>%
  kable("latex", longtable = TRUE, booktabs = TRUE,
        caption = "The ATOP scale questions for the children's survey.",
        col.names = c("Original", "French", "Dutch")) %>%
  kable_styling(latex_options = c("repeat_header"), font_size = 9) %>%
  column_spec(1:3, width = "3in") %>%
  landscape()
for (row in seq(1, nrow(atop_key_groups))) {
  tbl <- tbl %>%
    kableExtra::group_rows(atop_key_groups[row,1], start_row = atop_key_groups[row,2],
               end_row = atop_key_groups[row,3], underline = TRUE)
}
tbl
```




```{r nc-translation, message=FALSE, warning=FALSE, include=TRUE,  echo = FALSE}
tbl <- nc_key %>%
  dplyr::select(question_text_english, question_text_french,
                question_text_dutch) %>%
  kable("latex", longtable = TRUE, booktabs = TRUE,
        caption = "The NC scale questions for the children's survey.",
        col.names = c("Original", "French", "Dutch")) %>%
  kable_styling(latex_options = c("repeat_header"), font_size = 9) %>%
  column_spec(1:3, width = "3in") %>%
  landscape()
tbl
```

```{r reps-translation, message=FALSE, warning=FALSE, include=TRUE,  echo = FALSE}
tbl <- reps_key %>%
  mutate(question_text_english = ifelse(
    ommit_if_short_survey,
    paste0(question_text_english, "*"),
    question_text_english
  )) %>%
  dplyr::select(question_text_english, question_text_french,
                question_text_dutch) %>%
  kable("latex", longtable = TRUE, booktabs = TRUE,
        caption = "The REPS scale questions for parents. Questions with a * are omitted in the shortened survey.",
        col.names = c("Original", "French", "Dutch")) %>%
  kable_styling(latex_options = c("repeat_header"), font_size = 9) %>%
  column_spec(1:3, width = "3in") %>%
  landscape()
tbl
```

```{r atop-translation, message=FALSE, warning=FALSE, include=TRUE,  echo = FALSE}
tbl <- atop_key_p %>%
  mutate(question_text_english = ifelse(
    ommit_if_short_survey,
    paste0(question_text_english, "*"),
    question_text_english
  )) %>%
  dplyr::select(question_text_english, question_text_french,
                question_text_dutch) %>%
  kable("latex", longtable = TRUE, booktabs = TRUE,
        caption = "The outdoor play questions for the parents. Questions with a * are omitted in the shortened survey.",
        col.names = c("Original", "French", "Dutch")) %>%
  kable_styling(latex_options = c("repeat_header"), font_size = 9) %>%
  column_spec(1:3, width = "3in") %>%
  landscape()
tbl
```



\clearpage

# Additional information for the confirmatory factor analyses

In this section, we first elaborate on the calculation of the composite reliability measures; McDonald's $\omega$ and Chronbach Alpha.

The figures in this sections graphically show the descriptive statistics for Dutch-speaking and French-speaking children or parents separately. Children / parents from the bilingual school are included in both since it was not recorded in which language they answered.

In this section, we also show the standardized and unstandardized coefficient estimates and standard errors for each of the final CFA models.

For the REPS scale, an additional subsection investigates whether two additional statement on washing hands and playing in the rain could supplement the REPS scale.

## Calculating composite reliability {#comprel}

<!-- For reference: https://www.rdocumentation.org/packages/semTools/versions/0.4-9/topics/reliability -> we use omega_3 and alpha-->

We use the compRelSEM function from the semTools R package to calculate McDonald's $\omega$ and Chronbach Alpha.

The general formula implemented in the function to calculate McDonald's $\omega$ (sometimes referred to as hierarchical omega) is:

$$\omega = \frac{(\sum^k_{i=1}\lambda_i)^2 Var(\psi)}{\mathbf{1}^\intercal \hat{\Sigma} \mathbf{1}}$$ 

where $k$ is the number of items in a factor, $\lambda_i$ is the factor loading of item $i$, $\psi$ is the factor variance, and $\hat{\Sigma}$ is the observed covariance matrix. A $k$-dimensional vector of ones, $\mathbf{1}$, is used to sum elements in the matrix $\hat{\Sigma}$. 

Cronbach Alpha is calculated as:

$$\alpha = \frac{k}{k-1} \biggr[1-\frac{\sum^k_{i=1} \sigma_{ii}}{\sum^k_{i=1} \sigma_{ii} + 2\sum_{i<j}\sigma_{ij}}\biggr]$$

where $\sigma_{ii}$ is the observed variance of item $i$, $\sigma_{ij}$ is the observed covariance between items i and j. Cronbach Alpha depends on the assumption that each item contributes equally to the factor, i.e., all (unstandardized) loadings must be the same (called tau-equivalence). If this assumption is violated, true reliability will be underestimated.

\clearpage

## Attitude towards outdoor play (ATOP)

```{r atopkids-descriptives2, message=FALSE, warning=FALSE, include=TRUE, echo = FALSE, fig.cap= "Descriptive statistics for Dutch-speaking (left) and French-speaking (right) children for the ATOP scale items. Non-responses are not shown but taken into account when calculating the percentages.", fig.width = 6.5, fig.height = 6.5}
#####----------------------------APPENDIX:ATOP-----------------------------#####
likert_data_atop <- atop_data %>%
  as.data.frame() %>%
  left_join(children) %>%
  dplyr::filter(str_detect(community, "Dutch speaking")) %>%
  mutate(interpretation = factor(as.factor(interpretation),
                                 levels = c("Disagree", "Slightly disagree",
                                            "No response",
                                            "Moderately agree", "Agree"))) %>%
  dplyr::select(question_short, interpretation) %>%
  pivot_wider(names_from = question_short, values_from = interpretation,
              values_fn = list)
likert_data_atop2 <- as.data.frame(do.call(cbind,
                                          sapply(1:ncol(likert_data_atop),
                                                 FUN = function(x) {
                                                   likert_data_atop[[x]]
                                          })))
colnames(likert_data_atop2) <- names(likert_data_atop)
likert_data_atop <- likert_data_atop2 %>%
  mutate(across(think_clearly:getting_hurt, function(x) factor(as.factor(x),
                                      levels = 1:5,                      
                                      labels = c("Disagree",
                                                 "Slightly disagree",
                                                 "No response",
                                                 "Moderately agree",
                                                 "Agree"))))
names(likert_data_atop) <- atop_key$question_text_english
p_nl <- gglikert(likert_data_atop, sort = "none", y_label_wrap = 20,
                 labels_size = 2)
 

likert_data_atop <- atop_data %>%
  as.data.frame() %>%
  left_join(children) %>%
  dplyr::filter(str_detect(community, "French speaking")) %>%
  mutate(interpretation = factor(as.factor(interpretation),
                                 levels = c("Disagree", "Slightly disagree",
                                            "No response",
                                            "Moderately agree", "Agree"))) %>%
  dplyr::select(question_short, interpretation) %>%
  pivot_wider(names_from = question_short, values_from = interpretation,
              values_fn = list)
likert_data_atop2 <- as.data.frame(do.call(cbind,
                                          sapply(1:ncol(likert_data_atop),
                                                 FUN = function(x) {
                                                   likert_data_atop[[x]]
                                          })))
colnames(likert_data_atop2) <- names(likert_data_atop)
likert_data_atop <- likert_data_atop2 %>%
  mutate(across(think_clearly:getting_hurt, function(x) factor(as.factor(x),
                                      levels = 1:5,                      
                                      labels = c("Disagree",
                                                 "Slightly disagree",
                                                 "No response",
                                                 "Moderately agree",
                                                 "Agree"))))
names(likert_data_atop) <- atop_key$question_text_english

p_fr <- gglikert(likert_data_atop, sort = "none", y_label_wrap = 20,
                 labels_size = 2) +
  theme(axis.text.y = element_blank())
p_nl + p_fr + plot_layout(guides = "collect") &
  theme(legend.position = "bottom",
        text = element_text(size = 9))
```


```{r atop-loadings}
est <- parameterEstimates(fit_sameloadings_atop) %>%
  mutate(type = ifelse(op == "=~",
                       "loading",
                       ifelse(op == "~1",
                              "intercept",
                              ifelse(lhs == rhs,
                                     "variance",
                                     "covariance"))),
         estimate = sprintf("%.3f %s", est, gtools::stars.pval(pvalue))) %>%
  mutate(link = ifelse(type %in% c("loading", "covariance"),
                       sprintf("%s %s %s", lhs, op, rhs),
                       lhs)) %>%
  dplyr::select(type, link, estimate, se)
t <- cbind(est[1:(nrow(est)/2),], est[(nrow(est)/2+1):nrow(est),-c(1,2)])
t[, -1] %>%
  kable(booktabs = TRUE,
        caption = "Unstandardized coefficient estimates and standard errors for the metric measurement invariance model for ATOP, comparing Dutch-speaking versus French-speaking respondents",
        col.names = c("", "Estimate", "SE", "Estimate", "SE"),
        digits = 3) %>%
  kableExtra::kable_styling(font_size = 9) %>%
  kableExtra::add_header_above(c("", "Dutch speaking" = 2,
                                 "French speaking" = 2)) %>%
  kableExtra::group_rows(start_row = which(t$type == "loading")[1],
                         end_row = max(which(t$type == "loading")),
                         "Loadings") %>%
  kableExtra::group_rows(start_row = which(t$type == "intercept")[1],
                         end_row = max(which(t$type == "intercept")),
                         "Intercept") %>%
  kableExtra::group_rows(start_row = 14,
                         end_row = 26,
                         "Variance") %>%
  kableExtra::group_rows(start_row = 12,
                         end_row = 13,
                         "Covariance") %>%
  kableExtra::group_rows(start_row = 27,
                         end_row = 27,
                         "Covariance") %>%
  kableExtra::add_footnote(
    label = ". p < 0.1, * p <.05, ** p <.01, *** p <.001")
#which(t$type == "covariance")
#which(t$type == "variance")
```

```{r atop-loadings2}
est <- standardizedSolution(fit_sameloadings_atop) %>%
  mutate(type = ifelse(op == "=~",
                       "loading",
                       ifelse(op == "~1",
                              "intercept",
                              ifelse(lhs == rhs,
                                     "variance",
                                     "covariance"))),
         estimate = sprintf("%.3f %s", `est.std`, gtools::stars.pval(pvalue))) %>%
  mutate(link = ifelse(type %in% c("loading", "covariance"),
                       sprintf("%s %s %s", lhs, op, rhs),
                       lhs)) %>%
  dplyr::select(type, link, estimate, se)
t <- cbind(est[1:(nrow(est)/2),], est[(nrow(est)/2+1):nrow(est),-c(1,2)])
t[, -1] %>%
  kable(booktabs = TRUE,
        caption = "Standardized coefficient estimates and standard errors for the metric measurement invariance model for ATOP, comparing Dutch-speaking versus French-speaking respondents",
        col.names = c("", "Estimate", "SE", "Estimate", "SE"),
        digits = 3) %>%
  kableExtra::kable_styling(font_size = 9) %>%
  kableExtra::add_header_above(c("", "Dutch speaking" = 2,
                                 "French speaking" = 2)) %>%
  kableExtra::group_rows(start_row = which(t$type == "loading")[1],
                         end_row = max(which(t$type == "loading")),
                         "Loadings") %>%
  kableExtra::group_rows(start_row = which(t$type == "intercept")[1],
                         end_row = max(which(t$type == "intercept")),
                         "Intercept") %>%
  kableExtra::group_rows(start_row = 14,
                         end_row = 26,
                         "Variance") %>%
  kableExtra::group_rows(start_row = 12,
                         end_row = 13,
                         "Covariance") %>%
  kableExtra::group_rows(start_row = 27,
                         end_row = 27,
                         "Covariance") %>%
  kableExtra::add_footnote(
    label = ". p < 0.1, * p <.05, ** p <.01, *** p <.001")
#which(t$type == "covariance")
#which(t$type == "variance")
```

\clearpage

## Nature connectedness (NC)

```{r nc-descriptives2, message=FALSE, warning=FALSE, include=TRUE, echo = FALSE, fig.cap = "Descriptive statistics for Dutch-speaking (left) and French-speaking (right) children for the NC scale items. Non-responses are not shown but taken into account when calculating the percentages.", fig.width = 6.5, fig.height = 5}
#####--------------------APPENDIX: NATURE CONNECTEDNESS--------------------#####
likert_data_nc <- nc_data %>%
  as.data.frame() %>%
  left_join(children) %>%
  dplyr::filter(str_detect(community, "Dutch speaking")) %>%
  mutate(interpretation = factor(as.factor(interpretation),
                                 levels = c("Disagree", "Slightly disagree",
                                            "No response", "Don't know",
                                            "Moderately agree", "Agree"))) %>%
  dplyr::select(question_short, interpretation) %>%
  pivot_wider(names_from = question_short, values_from = interpretation,
              values_fn = list)
likert_data_nc2 <- as.data.frame(do.call(cbind,
                                          sapply(1:ncol(likert_data_nc),
                                                 FUN = function(x) {
                                                   likert_data_nc[[x]]
                                          })))
colnames(likert_data_nc2) <- names(likert_data_nc)
likert_data_nc <- likert_data_nc2 %>%
  mutate(across(beauty:part_of, function(x) factor(as.factor(x),
                                      levels = 1:6,                      
                                      labels = c("Disagree",
                                                 "Slightly disagree",
                                                 "No response", "Don't know",
                                                 "Moderately agree", "Agree"))))
names(likert_data_nc) <- nc_key$question_text_english
p_nl <- gglikert(likert_data_nc,
                 exclude_fill_values = "No response",
                 sort = "none", y_label_wrap = 20,
                 labels_size = 2)
 

likert_data_nc <- nc_data %>%
  as.data.frame() %>%
  left_join(children) %>%
  dplyr::filter(str_detect(community, "French speaking")) %>%
  mutate(interpretation = factor(as.factor(interpretation),
                                 levels = c("Disagree", "Slightly disagree",
                                            "No response", "Don't know",
                                            "Moderately agree", "Agree"))) %>%
  dplyr::select(question_short, interpretation) %>%
  pivot_wider(names_from = question_short, values_from = interpretation,
              values_fn = list)
likert_data_nc2 <- as.data.frame(do.call(cbind,
                                          sapply(1:ncol(likert_data_nc),
                                                 FUN = function(x) {
                                                   likert_data_nc[[x]]
                                          })))
colnames(likert_data_nc2) <- names(likert_data_nc)
likert_data_nc <- likert_data_nc2 %>%
  mutate(across(beauty:part_of, function(x) factor(as.factor(x),
                                      levels = 1:6,                      
                                      labels = c("Disagree",
                                                 "Slightly disagree",
                                                 "No response", "Don't know",
                                                 "Moderately agree", "Agree"))))
names(likert_data_nc) <- nc_key$question_text_english

p_fr <- gglikert(likert_data_nc, sort = "none",
                 exclude_fill_values = "No response", y_label_wrap = 20,
                 labels_size = 2) +
  theme(axis.text.y = element_blank())
p_nl + p_fr + plot_layout(guides = "collect") &
  theme(legend.position = "bottom",
        text = element_text(size = 9))
```

```{r nc-loadings}
est <- parameterEstimates(fit_sameloadings_nc) %>%
  mutate(type = ifelse(op == "=~",
                       "loading",
                       ifelse(op == "~1",
                              "intercept",
                              ifelse(lhs == rhs,
                                     "variance",
                                     "covariance"))),
         estimate = sprintf("%.3f %s", est, gtools::stars.pval(pvalue))) %>%
  mutate(link = ifelse(type %in% c("loading", "covariance"),
                       sprintf("%s %s %s", lhs, op, rhs),
                       lhs)) %>%
  dplyr::select(type, link, estimate, se)
t <- cbind(est[1:(nrow(est)/2),], est[(nrow(est)/2+1):nrow(est),-c(1,2)])
t[, -1] %>%
  kable(booktabs = TRUE,
        caption = "Unstandardized coefficient estimates and standard errors for the metric measurement invariance model for NC, comparing Dutch-speaking versus French-speaking respondents",
        col.names = c("", "Estimate", "SE", "Estimate", "SE"),
        digits = 3) %>%
  kableExtra::kable_styling(font_size = 9) %>%
  kableExtra::add_header_above(c("", "Dutch speaking" = 2,
                                 "French speaking" = 2)) %>%
  kableExtra::group_rows(start_row = which(t$type == "loading")[1],
                         end_row = max(which(t$type == "loading")),
                         "Loadings") %>%
  kableExtra::group_rows(start_row = which(t$type == "intercept")[1],
                         end_row = max(which(t$type == "intercept")),
                         "Intercept") %>%
  kableExtra::group_rows(start_row = 8,
                         end_row = 14,
                         "Variance") %>%
  kableExtra::group_rows(start_row = 7,
                         end_row = 7,
                         "Covariance") %>%
  kableExtra::add_footnote(label = "* p <.05, ** p <.01, *** p <.001")
#which(t$type == "covariance")
#which(t$type == "variance")
```

```{r nc-loadings2}
est <- standardizedSolution(fit_sameloadings_nc) %>%
  mutate(type = ifelse(op == "=~",
                       "loading",
                       ifelse(op == "~1",
                              "intercept",
                              ifelse(lhs == rhs,
                                     "variance",
                                     "covariance"))),
         estimate = sprintf("%.3f %s", `est.std`, gtools::stars.pval(pvalue))) %>%
  mutate(link = ifelse(type %in% c("loading", "covariance"),
                       sprintf("%s %s %s", lhs, op, rhs),
                       lhs)) %>%
  dplyr::select(type, link, estimate, se)
t <- cbind(est[1:(nrow(est)/2),], est[(nrow(est)/2+1):nrow(est),-c(1,2)])
t[, -1] %>%
  kable(booktabs = TRUE,
        caption = "Standardized coefficient estimates and standard errors for the metric measurement invariance model for NC, comparing Dutch-speaking versus French-speaking respondents",
        col.names = c("", "Estimate", "SE", "Estimate", "SE"),
        digits = 3) %>%
  kableExtra::kable_styling(font_size = 9) %>%
  kableExtra::add_header_above(c("", "Dutch speaking" = 2,
                                 "French speaking" = 2)) %>%
  kableExtra::group_rows(start_row = which(t$type == "loading")[1],
                         end_row = max(which(t$type == "loading")),
                         "Loadings") %>%
  kableExtra::group_rows(start_row = which(t$type == "intercept")[1],
                         end_row = max(which(t$type == "intercept")),
                         "Intercept") %>%
  kableExtra::group_rows(start_row = 8,
                         end_row = 14,
                         "Variance") %>%
  kableExtra::group_rows(start_row = 7,
                         end_row = 7,
                         "Covariance") %>%
  kableExtra::add_footnote(label = "* p <.05, ** p <.01, *** p <.001")
#which(t$type == "covariance")
#which(t$type == "variance")
```

\clearpage

## Risk engagement and protection survey (REPS)

```{r reps-descriptives2, message=FALSE, warning=FALSE, include=TRUE, echo = FALSE, fig.cap = "Descriptive statistics for Dutch-speaking (left) and French-speaking (right) parents for the REPS scale items.", fig.width = 6.5, fig.height = 9, eval = TRUE}
#####----------------------------APPENDIX: REPS----------------------------#####
likert_data_reps <- reps_data %>%
  as.data.frame() %>%
  rbind(c("10-5X-03", "1", "Single response", "wash_hands", "x6_14", NA)) %>% #this line is missing from the data
  left_join(children) %>%
  dplyr::filter(str_detect(community, "Dutch speaking")) %>%
  dplyr::select(question_short, response) %>%
  pivot_wider(names_from = question_short, values_from = response,
              values_fn = list)
likert_data_reps2 <- as.data.frame(do.call(cbind,
                                          sapply(1:ncol(likert_data_reps),
                                                 FUN = function(x) {
                                                   likert_data_reps[[x]]
                                          })))
colnames(likert_data_reps2) <- names(likert_data_reps)
likert_data_reps <- likert_data_reps2 %>%
  dplyr::select(reps_key %>%
                  arrange(factor) %>%
                  dplyr::pull(question_short))#order according to the factor
names(likert_data_reps) <-
  unname(unlist(reps_key[
    match(names(likert_data_reps),reps_key$question_short),
    "question_text_english"]))
p_nl <- gglikert(likert_data_reps, sort = "none", y_label_wrap = 25,
                 labels_size = 1.5)


#How often is each question answered in each of the communities?
nb_answered <- reps_data %>%
  left_join(children) %>% 
  group_by(question_code, question_short, community) %>%
  summarize(n = n_distinct(child_id)) %>%
  ungroup()
#wash_hands is never answered in the french community 
  
  
full_available <- reps_data %>%
  group_by(child_id) %>%
  summarize(n = n()) %>%
  mutate(rest = (n %% 16)) %>%
  left_join(children) %>% 
  filter((community == "Dutch speaking" & n %% 16 == 0) |
           (community == "French speaking" & n %% 15 == 0)) %>%
  dplyr::pull(child_id) #parents of these children filled in all questions


likert_data_reps <- reps_data %>%
  as.data.frame() %>%
  left_join(children) %>%
  dplyr::filter(str_detect(community, "French speaking") &
                  child_id %in% full_available) %>%
  dplyr::select(question_short, response) %>%
  pivot_wider(names_from = question_short, values_from = response,
              values_fn = list)
likert_data_reps2 <- as.data.frame(do.call(cbind,
                                          sapply(1:(ncol(likert_data_reps)),
                                                 FUN = function(x) {
                                                   likert_data_reps[[x]]
                                          })))
colnames(likert_data_reps2) <- names(likert_data_reps)
likert_data_reps <- likert_data_reps2 %>%
  dplyr::select(reps_key %>%
                  dplyr::filter(reps_key$question_short != "wash_hands") %>%
                  arrange(factor) %>%
                  dplyr::pull(question_short))
names(likert_data_reps) <-
  unname(unlist(reps_key[
    match(names(likert_data_reps),reps_key$question_short),
    "question_text_english"]))
factorize <- function(x){
  out <- factor(as.factor(x), levels = as.character(seq(1,7)))
  return(out)
}
p_fr <- likert_data_reps %>%
  mutate_at(1:15, factorize) %>%
  gglikert(sort = "none", y_label_wrap = 25,
           labels_size = 1.5)

p_nl + p_fr + plot_layout(guides = "collect") &
  theme(legend.position = "bottom",
        text = element_text(size = 8))
```


```{r reps-loadings}
est <- parameterEstimates(fit_free_reps) %>%
  mutate(type = ifelse(op == "=~",
                       "loading",
                       ifelse(op == "~1",
                              "intercept",
                              ifelse(lhs == rhs,
                                     "variance",
                                     "covariance"))),
         estimate = sprintf("%.3f %s", est, gtools::stars.pval(pvalue))) %>%
  mutate(link = ifelse(type %in% c("loading", "covariance"),
                       sprintf("%s %s %s", lhs, op, rhs),
                       lhs),
         type = factor(as.factor(type),
                       levels = c("loading", "covariance", "intercept",
                                  "variance"),
                       ordered = TRUE)) %>%
  dplyr::select(type, link, estimate, se)
t <- cbind(est[1:(nrow(est)/2), ], est[(nrow(est) / 2 + 1):nrow(est), -c(1, 2)])

t[1:31, -1] %>%
  kable(booktabs = TRUE,
        caption = "Unstandardized coefficient estimates and standard errors for configural model for REPS, comparing Dutch-speaking versus French-speaking respondents.",
        col.names = c("", "Estimate", "SE", "Estimate", "SE"),
        digits = 3) %>%
  kableExtra::kable_styling(font_size = 9) %>%
  kableExtra::add_header_above(c("", "Dutch speaking" = 2,
                                 "French speaking" = 2)) %>%
  kableExtra::group_rows(start_row = which(t$type == "loading")[1],
                         end_row = max(which(t$type == "loading")),
                         "Loadings") %>%
  kableExtra::group_rows(start_row = which(t$type == "variance")[1],
                         end_row = max(which(t$type == "variance")),
                         "Variance") %>%
  kableExtra::group_rows(start_row = which(t$type == "covariance")[1],
                         end_row = max(which(t$type == "covariance")),
                         "Covariance") %>%
  kableExtra::add_footnote(label = "* p <.05, ** p <.01, *** p <.001")
#which(t$type == "covariance")
#which(t$type == "variance")
```

```{r reps-loadings2}
t[32:47, -1] %>%
  kable(booktabs = TRUE,
        caption = "Unstandardized coefficient estimates and standard errors for the configural model for REPS, comparing Dutch-speaking versus French-speaking respondents (continued).",
        col.names = c("", "Estimate", "SE", "Estimate", "SE"),
        digits = 3,
        row.names = FALSE) %>%
  kableExtra::kable_styling(font_size = 9) %>%
  kableExtra::add_header_above(c("", "Dutch speaking" = 2,
                                 "French speaking" = 2)) %>%
  kableExtra::group_rows(start_row = 1,
                         end_row = 16,
                         "Intercept") %>%
  kableExtra::add_footnote(label = "* p <.05, ** p <.01, *** p <.001")
#which(t$type == "covariance")
#which(t$type == "variance")
```

```{r reps-loadings3}
est <- standardizedSolution(fit_free_reps) %>%
  mutate(type = ifelse(op == "=~",
                       "loading",
                       ifelse(op == "~1",
                              "intercept",
                              ifelse(lhs == rhs,
                                     "variance",
                                     "covariance"))),
         estimate = sprintf("%.3f %s", `est.std`, gtools::stars.pval(pvalue))) %>%
  mutate(link = ifelse(type %in% c("loading", "covariance"),
                       sprintf("%s %s %s", lhs, op, rhs),
                       lhs),
         type = factor(as.factor(type),
                       levels = c("loading", "covariance", "intercept",
                                  "variance"),
                       ordered = TRUE)) %>%
  dplyr::select(type, link, estimate, se)
t <- cbind(est[1:(nrow(est)/2),], est[(nrow(est)/2+1):nrow(est),-c(1,2)])
t[1:31, -1] %>%
  kable(booktabs = TRUE,
        caption = "Standardized coefficient estimates and standard errors for the configural model for REPS, comparing Dutch-speaking versus French-speaking respondents.",
        col.names = c("", "Estimate", "SE", "Estimate", "SE"),
        digits = 3) %>%
  kableExtra::kable_styling(font_size = 9) %>%
  kableExtra::add_header_above(c("", "Dutch speaking" = 2,
                                 "French speaking" = 2)) %>%
  kableExtra::group_rows(start_row = which(t$type == "loading")[1],
                         end_row = max(which(t$type == "loading")),
                         "Loadings") %>%
  kableExtra::group_rows(start_row = which(t$type == "variance")[1],
                         end_row = max(which(t$type == "variance")),
                         "Variance") %>%
  kableExtra::group_rows(start_row = which(t$type == "covariance")[1],
                         end_row = max(which(t$type == "covariance")),
                         "Covariance") %>%
  kableExtra::add_footnote(label = "* p <.05, ** p <.01, *** p <.001")
#which(t$type == "covariance")
#which(t$type == "variance")
```

```{r reps-loadings4}
t[32:47, -1] %>%
  kable(booktabs = TRUE,
        caption = "Standardized coefficient estimates and standard errors for the configural model for REPS, comparing Dutch-speaking versus French-speaking respondents (continued).",
        col.names = c("", "Estimate", "SE", "Estimate", "SE"),
        digits = 3,
        row.names = FALSE) %>%
  kableExtra::kable_styling(font_size = 9) %>%
  kableExtra::add_header_above(c("", "Dutch speaking" = 2,
                                 "French speaking" = 2)) %>%
  kableExtra::group_rows(start_row = 1,
                         end_row = 16,
                         "Intercept") %>%
  kableExtra::add_footnote(label = "* p <.05, ** p <.01, *** p <.001")
#which(t$type == "covariance")
#which(t$type == "variance")
```

\clearpage

### Exploratory factor analysis for additional statements {#repsefa}

Two additional statements were added to the REPS questions:

- How often do you allow your child to play outside when it is raining?
- Should your child wash his / her hands after outdoor play?

We test whether these two additional items can complement the 14 original REPS items. We first test  whether they fit, using only the complete observations (123 parent who filled in all 16 items).
Since there are many missing values for the "washing hands" item (it was forgotten in the French translation), we also use multiple imputation to impute all missing values. This will allow us to use the data for all 238 parents in a second EFA. The method of imputation is based on Fully Conditional Specification, where each incomplete variable (item) is imputed by a separate model. As the items are scored on a continuous scale, predictive mean matching is applied, meaning real values are sampled from the data to fill in the blanks. Five imputed dataset are thus created and the covariance matrices of the imputed data sets (needed for the EFA) are combined using Rubin's rules [@rubin2018multiple; @JSSv045i03].

We use EFA to check whether these two additional items might fit any of the original REPS factors. The following Table 26 and 27 show that the two additional statements do not fit well with the original REPS scales, based on EFA with only the complete observations or on the whole data set, using multiple imputation. We see that neither play in rain nor washing hand indicators are represented well in the EFA.


```{r message=FALSE, warning=FALSE, include=FALSE, echo = FALSE, eval = TRUE}
#-------------1. Analysing only complete data (no missing answers)-------------#
df <- data_cfa_reps[complete.cases(data_cfa_reps[, -c(1, 2)]), -c(1, 2)]
pca <- prcomp(df)
scree1 <- screeplot(pca, type = "lines")#2 factors is best
covmat <- cov(data_cfa_reps[complete.cases(data_cfa_reps), -c(1, 2)])
cormat <- cor(data_cfa_reps[complete.cases(data_cfa_reps), -c(1, 2)])
efa_complete <- fa(cormat,
                   covar = FALSE,
                   2, rotate = "oblimin",
                   fm = "ml", n.obs = nrow(df))
tables_efa_complete <- fa_table(efa_complete,
                         title = "Results for the EFA and oblique rotation
                         and two factors, based on complete observations only.",
                         varlabels = str_wrap(reps_key$question_short,
                                              15))
tables_efa_complete$ind_table
#the two additional statements do not fit in either of the factors.
#the EFA further uncovers the original two factors although the statement "I encourage my child to do physical activity" is now part of the engagement with risk factor in stead of the protection factor.

#--------------------------------2. EFA with MI--------------------------------#
library(mifa)
set.seed(4)
mi <- mifa(data = data_cfa_reps[,-c(1, 2)])
fit <- fa(mi$cov_combined, n.obs = nrow(data_cfa_reps), nfactors = 2)
#fa.diagram(fit)
tables_atop <- fa_table(fit,
                         title = "Results for the EFA with multiple imputation and oblique rotation
                         and two factors.",
                         varlabels = str_wrap(reps_key$question_short,
                                              15))
tables_atop$ind_table
#Again, the washing hands and playing in the rain statements don't fit with
# either factor. "I encourage my child to do physical activity (with the least 
# risk of injury)." also does not fit well with either.
```

```{r reps-efa1}
tables_efa_complete$ind_table
```


```{r reps-efa2}
tables_atop$ind_table# %>%
  # row_spec(15, background = "#D93B3B") %>%
  # row_spec(16, background = "#D93B3B")
```

### Exploratory factor analysis with three or four factors {#reps-improve-fit}

In an attempt to improve the fit of the factor model, models with three or four factors were tested.

EFA with three factors suggests to split up REPS_protection_from_injury into two factors. REPS_risk_engagement is still measured by the same 6 statements. One statement “encourage_safe_activities” does not fit with any of the latent factors (see Table \@ref(tab:reps-efa-3)).

EFA with four factors suggests to split up REPS_protection_from_injury into two factors. The item “promote physical challenges” is removed from  REPS_risk_engagement and becomes its own latent factor. One statement, “encourage_safe_activities”, again does not fit with any of the latent factors (see Table \@ref(tab:reps-efa-4)).

Looking at the fit and composite reliability of the model with 3 and 4 factors (Table \@ref(tab:reps-34-fit) and \@ref(tab:reps-34-cr) respectively), we conclude that both fit and reliability did not consistently improve compared to the original model with two factors.
 
```{r include = FALSE, warning = FALSE, message = FALSE}
#---------------------------------REPS with 3 or 4 factors---------------------#
df <- data_cfa_reps %>%
  dplyr::select(-play_in_rain, -wash_hands)
df <- df[complete.cases(df[, -c(1, 2)]), -c(1, 2)]
pca <- prcomp(df)
screeplot(pca, type = "lines")#2-4 factors is best
covmat <- cov(df)
cormat <- cor(df)
fa.parallel(cormat, n.obs = nrow(df))#2 factors is best
vss(cormat, n.obs = nrow(df)) #-> 2 or 4 is best

#-------------------------------3 factor model---------------------------------#
efa_3 <- fa(cormat,
                   covar = FALSE,
                   3, rotate = "oblimin",
                   fm = "ml", n.obs = nrow(df))
model_reps <- "protection_from_injury1 =~ 1*prevention_importance + importance_supervision + limit_dangerous_activities + chance_of_injury
protection_from_injury2 =~ 1*concerned_injury + concerned_hazards + avoid_risk
          risk_engagement =~ 1*promote_physical_challenges + physical_limits + explore_new_environments + benefits_outweigh_risk + importance_managing_risk + risk_self_confidence"
likert_data_reps <- reps_data %>%
  as.data.frame() %>%
  mutate(interpretation = response) %>%
  rbind(c("10-5X-03", "1", "Single response", "wash_hands", "x6_14", NA,
          NA)) %>% #this line is missing from the data
  dplyr::select(question_short, interpretation, child_id) %>%
  mutate(interpretation = as.numeric(interpretation)) %>%#for some reason, this is changed to character
  dplyr::group_by(child_id, question_short) %>% #There are children whose parents filled it in more than once
  dplyr::summarise(interpretation = mean(interpretation, na.rm = TRUE),
                   .groups = "drop") %>%
  pivot_wider(names_from = question_short, values_from = interpretation,
              id_cols = child_id) %>%
  left_join(children) %>%
  left_join(schools)
fit_free_reps3 <- cfa(model_reps,
                     data = likert_data_reps %>%
                       filter(community != "Dutch speaking.French speaking"),
                     group = "community")
fit_sameloadings_reps3 <- cfa(model_reps,
                             data = likert_data_reps %>%
                               filter(community !=
                                        "Dutch speaking.French speaking"),
                             group = "community",
                             group.equal = c("loadings"))
fit_sameloadingsinterc_reps3 <- cfa(model_reps,
                                   data = likert_data_reps %>%
                                     filter(community !=
                                              "Dutch speaking.French speaking"),
                                   group = "community",
                                   group.equal = c("loadings", "intercepts"))

anov_reps_metric <- anova(fit_free_reps3, fit_sameloadings_reps3) #metric model cannot be rejected
anov_reps_strong <- anova(fit_free_reps3, fit_sameloadingsinterc_reps3)
#interpret the fit:
interpret(fit_sameloadings_reps3) #they almost all show poor fit
fitmeasures(fit_sameloadings_reps3, c("chisq", "df", "pvalue", "cfi",
                                     "tli", "rmsea", "srmr", "AIC",
                                     "BIC"))
cr_omega_reps3 <- compRelSEM(fit_sameloadings_reps3, tau.eq = F, obs.var = T)
cr_alpha_reps3 <- compRelSEM(fit_sameloadings_reps3, tau.eq = T, obs.var = T)
#-------------------------------4 factor model---------------------------------#
efa_4 <- fa(cormat,
                   covar = FALSE,
                   4, rotate = "oblimin",
                   fm = "ml", n.obs = nrow(df))
model_reps <- "protection_from_injury1 =~ 1*prevention_importance + importance_supervision + limit_dangerous_activities + chance_of_injury
protection_from_injury2 =~ 1*concerned_injury + concerned_hazards + avoid_risk
          risk_engagement =~ 1*physical_limits + explore_new_environments + benefits_outweigh_risk + importance_managing_risk + risk_self_confidence
risk_engagement2 =~ 1*promote_physical_challenges"
fit_free_reps4 <- cfa(model_reps,
                     data = likert_data_reps %>%
                       filter(community != "Dutch speaking.French speaking"),
                     group = "community")
fit_sameloadings_reps4 <- cfa(model_reps,
                             data = likert_data_reps %>%
                               filter(community !=
                                        "Dutch speaking.French speaking"),
                             group = "community",
                             group.equal = c("loadings"))
fit_sameloadingsinterc_reps4 <- cfa(model_reps,
                                   data = likert_data_reps %>%
                                     filter(community !=
                                              "Dutch speaking.French speaking"),
                                   group = "community",
                                   group.equal = c("loadings", "intercepts"))

anov_reps_metric <- anova(fit_free_reps4, fit_sameloadings_reps4) #metric model cannot be rejected
anov_reps_strong <- anova(fit_free_reps4, fit_sameloadingsinterc_reps4)
#interpret the fit:
interpret(fit_sameloadings_reps4) #they all show poor fit
fitmeasures(fit_sameloadings_reps4, c("chisq", "df", "pvalue", "cfi",
                                     "tli", "rmsea", "srmr", "AIC",
                                     "BIC"))
cr_omega_reps4 <- compRelSEM(fit_sameloadings_reps4, tau.eq = F, obs.var = T)
cr_alpha_reps4 <- compRelSEM(fit_sameloadings_reps4, tau.eq = T, obs.var = T)
```

```{r reps-efa-3}
tables_reps_3 <-
  fa_table(efa_3,
           fnames = c("risk engagement", "protection from injury1", "protection from injury2"),
           title = "Results for the EFA of the REPS scale, using oblique rotation and three factors."
  )
tables_reps_3$ind_table %>%
  row_spec(13, background = "#D93B3B") %>%
  kableExtra::column_spec(1, width = "1.2in") %>%
  kableExtra::column_spec(2:7, width = "0.6in")
```

```{r reps-efa-4}
tables_reps_4 <-
  fa_table(efa_4,
           fnames = c("risk engagement1", "protection from injury1", "protection from injury2", "risk engagement2"),
           title = "Results for the EFA of the REPS scale, using oblique rotation and four factors."
  )
tables_reps_4$ind_table %>%
  row_spec(5, background = "#D93B3B") %>%
  kableExtra::column_spec(1, width = "1.2in") %>%
  kableExtra::column_spec(2:7, width = "0.6in")
```

```{r reps-34-fit}
data.frame(
  factor3 = fitmeasures(fit_sameloadings_reps3,
                        c("chisq", "df", "pvalue", "cfi", "tli", "rmsea",
                          "srmr", "AIC", "BIC")),
  factor4 = fitmeasures(fit_sameloadings_reps4,
                        c("chisq", "df", "pvalue", "cfi", "tli", "rmsea",
                          "srmr", "AIC", "BIC"))
) %>%
  dplyr::mutate_if(is.numeric, avoid_scientif_notation) %>%
  kable(booktabs = TRUE,
        col.names = c("3-factor model", "4-factor model"),
        caption = "Fit measures for the REPS models with three or four factors.") %>%
  kableExtra::kable_styling()
```

```{r reps-34-cr}
cr_omega_reps3 %>%
  rbind(cr_omega_reps4) %>%
  kable(booktabs = TRUE,
        col.names = c("", "protection_from_injury1", "protection_from_injury2", "risk_engagement1"),
        caption = "Composite reliability (omega) for the REPS models with three or four factors.") %>%
  kableExtra::kable_styling() %>%
  kableExtra::group_rows("3-factor model", start_row = 1, end_row = 2) %>%
  kableExtra::group_rows("4-factor model", start_row = 3, end_row = 4)
```

\clearpage

## Outdoor play frequency

The parents' questionnaire included questions on how often their child actually plays outside or how much they spend indoors, doing homework, or behind a (tv / tablet / computer) screen.

```{r opp1, message=FALSE, warning=FALSE, include=TRUE, echo = FALSE, fig.cap = "Descriptive statistics for Dutch-speaking (left) and French-speaking (right) parents for the questions on how many days per week their child participates in...", fig.width = 6.5, fig.height = 4}
#####-------------------APPENDIX: OUTDOOR PLAY FREQUENCY-------------------#####
likert_data_atop <- atop_data_p1 %>%
  as.data.frame() %>%
  left_join(children) %>%
  dplyr::filter(!str_detect(community, "French")) %>%
  mutate(response = round(response)) %>%
  dplyr::select(activity, response) %>%
  pivot_wider(names_from = activity, values_from = response,
              values_fn = list)
likert_data_atop2 <- as.data.frame(do.call(cbind,
                                          sapply(1:ncol(likert_data_atop),
                                                 FUN = function(x) {
                                                   likert_data_atop[[x]]
                                          })))
colnames(likert_data_atop2) <- names(likert_data_atop)
likert_data_atop2 <- likert_data_atop2 %>%
  mutate_all(.funs = ~factor(as.factor(.x), levels = as.character(seq(0,7))))
p_nl <- gglikert(likert_data_atop2, sort = "none", y_label_wrap = 20,
                 labels_size = 2)
 

likert_data_atop <- atop_data_p1 %>%
  as.data.frame() %>%
  left_join(children) %>%
  dplyr::filter(str_detect(community, "French")) %>%
  mutate(response = round(response)) %>%
  dplyr::select(activity, response) %>%
  pivot_wider(names_from = activity, values_from = response,
              values_fn = list)
likert_data_atop2 <- as.data.frame(do.call(cbind,
                                          sapply(1:ncol(likert_data_atop),
                                                 FUN = function(x) {
                                                   likert_data_atop[[x]]
                                          })))
colnames(likert_data_atop2) <- names(likert_data_atop)
likert_data_atop2 <- likert_data_atop2 %>%
  mutate_all(.funs = ~factor(as.factor(.x), levels = as.character(seq(0,7))))

p_fr <- gglikert(likert_data_atop2, sort = "none", y_label_wrap = 20,
                 labels_size = 2)
p_nl + p_fr + plot_layout(guides = "collect") &
  theme(legend.position = "bottom",
        text = element_text(size = 9))
```

```{r opp2, message=FALSE, warning=FALSE, include=TRUE, echo = FALSE, fig.cap = "Descriptive statistics for Dutch-speaking (left) and French-speaking (right) parents for the questions 'Do you associate the following activity as typical outdoor playing behavior of you child?'", fig.width = 6.5, fig.height = 6.5}
likert_data_atop <- atop_data_p2 %>%
  as.data.frame() %>%
  left_join(children) %>%
  dplyr::filter(!str_detect(community, "French")) %>%
  mutate(response = ifelse(response == "association",
                           "Yes", 
                           ifelse(response == "no association",
                                  "No", "Maybe"))) %>%
  dplyr::select(activity, response) %>%
  pivot_wider(names_from = activity, values_from = response,
              values_fn = list)
likert_data_atop2 <- as.data.frame(do.call(cbind,
                                          sapply(1:ncol(likert_data_atop),
                                                 FUN = function(x) {
                                                   likert_data_atop[[x]]
                                          })))
colnames(likert_data_atop2) <- names(likert_data_atop)
likert_data_atop2 <- likert_data_atop2 %>%
  mutate_all(.funs = ~factor(as.factor(.x),
                             levels = c("Yes", "Maybe", "No")))
p_nl <- gglikert(likert_data_atop2, sort = "none", y_label_wrap = 25,
                 labels_size = 2)
 

likert_data_atop <- atop_data_p2 %>%
  as.data.frame() %>%
  left_join(children) %>%
  dplyr::filter(str_detect(community, "French")) %>%
  mutate(response = ifelse(response == "association",
                           "Yes", 
                           ifelse(response == "no association",
                                  "No", "Maybe"))) %>%
  dplyr::select(activity, response) %>%
  pivot_wider(names_from = activity, values_from = response,
              values_fn = list)
likert_data_atop2 <- as.data.frame(do.call(cbind,
                                          sapply(1:ncol(likert_data_atop),
                                                 FUN = function(x) {
                                                   likert_data_atop[[x]]
                                          })))
colnames(likert_data_atop2) <- names(likert_data_atop)
likert_data_atop2 <- likert_data_atop2 %>%
  mutate_all(.funs = ~factor(as.factor(.x),
                             levels = c("Yes", "Maybe", "No")))

p_fr <- gglikert(likert_data_atop2, sort = "none", y_label_wrap = 25,
                 labels_size = 2)
p_nl + p_fr + plot_layout(guides = "collect") &
  theme(legend.position = "bottom",
        text = element_text(size = 9))
```

```{r opp3, message=FALSE, warning=FALSE, include=TRUE, echo = FALSE, fig.cap = "Descriptive statistics for Dutch-speaking (left) and French-speaking (right) parents for the questions 'How many hours does your child spend on ... on an average weekday / weekend day?'", fig.width = 6.5, fig.height = 4}
likert_data_atop <- atop_data_p3 %>%
  as.data.frame() %>%
  left_join(children) %>%
  dplyr::filter(!str_detect(community, "French")) %>%
  mutate(
    activity = paste0(activity, "_", during),
    response = ifelse(response == "0 - < 1",
                      "0", 
                      ifelse(response == "< 1 - 1-2",
                             "1-2", ifelse(response == "1-2 - 2-3",
                                           "2-3",
                                           ifelse(str_detect(response, "3-4"),
                                                  "3-4", response))))) %>%
  dplyr::select(activity, response) %>%
  pivot_wider(names_from = activity, values_from = response,
              values_fn = list)
likert_data_atop2 <- as.data.frame(do.call(cbind,
                                          sapply(1:ncol(likert_data_atop),
                                                 FUN = function(x) {
                                                   likert_data_atop[[x]]
                                          })))
colnames(likert_data_atop2) <- names(likert_data_atop)
likert_data_atop2 <- likert_data_atop2 %>%
  mutate_all(.funs = ~factor(as.factor(.x),
                             levels = c("0", "< 1", "1-2", "2-3", "3-4",
                                        "> 4")))
p_nl <- gglikert(likert_data_atop2, sort = "none", y_label_wrap = 25,
                 labels_size = 2)
 
likert_data_atop <- atop_data_p3 %>%
  as.data.frame() %>%
  left_join(children) %>%
  dplyr::filter(str_detect(community, "French")) %>%
  mutate(
    activity = paste0(activity, "_", during),
    response = ifelse(response == "0 - < 1",
                      "0", 
                      ifelse(response == "< 1 - 1-2",
                             "1-2", ifelse(response == "1-2 - 2-3",
                                           "2-3",
                                           ifelse(str_detect(response, "3-4"),
                                                  "3-4", response))))) %>%
  dplyr::select(activity, response) %>%
  pivot_wider(names_from = activity, values_from = response,
              values_fn = list)
likert_data_atop2 <- as.data.frame(do.call(cbind,
                                          sapply(1:ncol(likert_data_atop),
                                                 FUN = function(x) {
                                                   likert_data_atop[[x]]
                                          })))
colnames(likert_data_atop2) <- names(likert_data_atop)
likert_data_atop2 <- likert_data_atop2 %>%
  mutate_all(.funs = ~factor(as.factor(.x),
                             levels = c("0", "< 1", "1-2", "2-3", "3-4",
                                        "> 4")))

p_fr <- gglikert(likert_data_atop2, sort = "none", y_label_wrap = 25,
                 labels_size = 2)
p_nl + p_fr + plot_layout(guides = "collect") &
  theme(legend.position = "bottom",
        text = element_text(size = 9))
```

\clearpage

### EFA for dimension reduction {#efa1}

We employ EFA for dimension reduction. We analyse statements with a continuous or discrete answer separately. Oblique rotation will be used in both factor analyses.

Firstly the questions of Figure \@ref(fig:opp1) and \@ref(fig:opp3) (8 statements) are converted to continuous variables (signifying the number of days per week or the number of hours per day). 
Using visual aids such as a scree plot and parallel analysis [@horn1965rationale], a model with 4 factors was chosen. Table 32 shows the factor loadings, communality, uniqueness and complexity. As can be seen in red, one statement does not fit well with any of the factors ("how many days per week does your child participate in other organized or structured outdoor activities (e.g. scouts, circus, ...)?"). This is not entirely surprising since there is very little variance in the answers; almost everyone answered 0 or 1 days per week. Each of the four underlying factors is assigned an appropriate name:

- "screentime" is high if the child spends a lot of time in from of a computer / tv / tablet screen.
- "indoor_activities" is high if the child spends a lot of time on organized, indoor sports.
- "homework" is high if the child spends a lot of time on homework.
- "organized_sports" is high if the child spends a lot of time on organized, outdoor sports (either on natural or artificial surface).

```{r efa-opp1}
tables_atop_p_mixed <-
  fa_table(efa_atop_p_mixed,
           fnames = c("screentime", "indoor activities", "homework",
                      "organized sports"),
           title = "Results for the EFA on the statements with continuous answers, using oblique rotation and four factors."
  )
tables_atop_p_mixed$ind_table %>%
  row_spec(4, background = "#D93B3B") %>%
  kableExtra::column_spec(1, width = "01in") %>%
  kableExtra::column_spec(2:8, width = "0.55in")
```

Secondly, the questions of Figure \@ref(fig:opp2) (14 statements) are converted to binary variables. As there are very few parents who answered "maybe", we consider this to be a "yes" answer and all responses are recoded to one for "yes" and zero for "no". As such, a tetrachoric correlation matrix is used for the EFA. Using visual aids such as a scree plot and parallel analysis [@horn1965rationale], a model with 5 factors was chosen. Table 33 shows the factor loadings, communality, uniqueness and complexity. Highlighted in red, we see that climbing_trees, building_camps, and stream_pond indicators are not represented well in the EFA because they load diffusely over multiple factors. However, this problem persists, even if the number of factors is increased or reduced. Each of the five underlying factors is assigned an appropriate name:

- "natural_play" is high if the child typically play in nature using branches to build camps, climbing trees, etc.
- "semi_natural_play" is high if the child typically plays in water but also for less nature-oriented outdoor activities such as biking or playing at a playground.
- "made_up_games_lingering" is high if the child typically likes to chill or linger outside or play made-up games.
- "hide_and_seek" is high if the child likes to play hide and seek.
- "unorganized sports" is high is the child typically plays sports such as football or basketball with neighborhood kids in stead of with a sports organization.

```{r efa-opp2}
tables_atop_p_binary <-
  fa_table(efa_atop_p_binary,
           fnames = c("natural play", "water games",
                      "made up games lingering",
                      "hide and seek", "unorganized sports"),
           title = "Results for the EFA on the statements with binary answers, using oblique rotation and five factors.")
tables_atop_p_binary$ind_table %>%
  row_spec(3, background = "#D93B3B") %>%
  row_spec(4, background = "#D93B3B") %>%
  row_spec(7, background = "#D93B3B") %>%
  kableExtra::column_spec(1, width = "0.8in") %>%
  kableExtra::column_spec(2:9, width = "0.5in")
```

## Independent mobility {#ap-im}

The parents' questionnaire included questions on how much freedom and independence they grant their child to roam their neighborhood, based on @jelleyman2019cross.

Figure \@ref(fig:im-nlvsfr) visualizes the answers for the Dutch and French survey separately.
French-speaking parents tend to let their children explore their neighborhood more but do not let them go to school or other places as often as Dutch-speaking parents.


```{r im-nlvsfr, message=FALSE, warning=FALSE, include=TRUE, echo = FALSE, fig.cap = "Descriptive statistics for Dutch-speaking (left) and French-speaking (right) parents for the questions on independent mobility.", fig.width = 6.5, fig.height = 5}
#####-------------------APPENDIX: INDEPENDENT MOBILITY---------------------#####
likert_data_im <- im_data %>%
  as.data.frame() %>%
  left_join(children) %>%
  dplyr::filter(!str_detect(community, "French")) %>%
  group_by(child_id, question_short) %>%
  summarize(response = first(response)) %>% # keep only one answer per child
  ungroup() %>%
  dplyr::select(question_short, response, child_id) %>%
  pivot_wider(names_from = question_short, values_from = response,
              id_cols = child_id)
p_nl <- gglikert(likert_data_im[, -1], sort = "none", y_label_wrap = 25,
                 labels_size = 2)
 

likert_data_im <- im_data %>%
  as.data.frame() %>%
  left_join(children) %>%
  dplyr::filter(!str_detect(community, "Dutch")) %>%
  group_by(child_id, question_short) %>%
  summarize(response = first(response)) %>% # keep only one answer per child
  ungroup() %>%
  dplyr::select(question_short, response, child_id) %>%
  pivot_wider(names_from = question_short, values_from = response,
              id_cols = child_id)

p_fr <- gglikert(likert_data_im[, -1], sort = "none", y_label_wrap = 25,
                 labels_size = 2)
p_nl + p_fr + plot_layout(guides = "collect") &
  theme(legend.position = "bottom",
        text = element_text(size = 9))
```

### EFA for dimension reduction {#efa2}

As with the questions on indoor and outdoor activities (appendix \@ref(efa1)), we use EFA with oblique rotation for dimension reduction on the independent mobility data. 

As there are very few parents who answered "maybe", we consider this to be a "yes" answer and all responses are recoded to one for "yes" and zero for "no". As such, the data can be analysed as binary data and a tetrachoric correlation matrix is used for the EFA. Using visual aids such as a scree plot and parallel analysis [@horn1965rationale], a model with 5 factors was chosen. Table 34 shows the factor loadings, communality, uniqueness and complexity. Highlighted in red, we see that the cycle_main_roads indicator is not represented well in the EFA because it loads diffusely over multiple factors. Each of the four underlying factors is assigned an appropriate name:

- "explore" is high if the parents allow the child to explore their neighborhood alone or with friends.
- "engage with traffic" is high if the parents allow the child to cross main roads or cycle on main roads, and if they can walk or bike to school or other places alone.
- "after dark", is high if the parents allow the child to go out after dark alone.
- "public transport" is high if the parents allow the child to use public transport alone.

```{r efa-im}
tables_im_data2 <-
  fa_table(efa_im_data2,
           fnames = c("explore", "engage with traffic",
                      "after dark",
                      "public transport"),
           title = "Results for the EFA and oblique rotation and four factors for the independent mobility questions."
  )
tables_im_data2$ind_table %>%
  row_spec(6, background = "#D93B3B") %>%
  kableExtra::column_spec(1, width = "1.25in") %>%
  kableExtra::column_spec(2:8, width = "0.5in")
```

\clearpage


# Structural equation model details

```{r sem-results, warning = FALSE, message = FALSE}
#####------------------APPENDIX: STRUCTURAL EQUATION MODEL-----------------#####
est <- parameterEstimates(sem_output) %>%
  mutate(type = ifelse(op == "=~",
                       "loading",
                       ifelse(op == "~1",
                              "intercept",
                              ifelse(op == "~",
                                     "regression",
                                     ifelse(lhs == rhs,
                                            "variance",
                                            "covariance")))),
         estimate = sprintf("%.3f %s", est, gtools::stars.pval(pvalue))) %>%
  mutate(link = ifelse(type %in% c("loading", "covariance", "regression"),
                       sprintf("%s %s %s", lhs, op, rhs),
                       lhs)) %>%
  dplyr::select(type, link, estimate, se) %>%
  mutate(type = factor(as.factor(type),
                       levels = c("loading", "covariance", "regression",
                                  "variance"),
                       ordered = TRUE)) %>%
  arrange(type)
est[, -1] %>%
  kable(booktabs = TRUE,
        caption = "Unstandardized coefficient estimates and standard errors for the SEM.",
        col.names = c("", "Estimate", "SE"),
        digits = 3,
        longtable = TRUE) %>%
  kableExtra::kable_styling(font_size = 9) %>%
  kableExtra::group_rows(start_row = which(est$type == "loading")[1],
                         end_row = max(which(est$type == "loading")),
                         "Loadings") %>%
  kableExtra::group_rows(start_row = which(est$type == "variance")[1],
                         end_row = max(which(est$type == "variance")),
                         "Variance") %>%
  kableExtra::group_rows(start_row = which(est$type == "covariance")[1],
                         end_row = max(which(est$type == "covariance")),
                         "Covariance") %>%
  kableExtra::group_rows(start_row = which(est$type == "regression")[1],
                         end_row = max(which(est$type == "regression")),
                         "Regression") %>%
  kable_styling(latex_options = c("repeat_header"), font_size = 9) %>%
  kableExtra::add_footnote(label = "* p <.05, ** p <.01, *** p <.001")
#which(t$type == "covariance")
#which(t$type == "variance")
```

```{r sem-results-std, warning = FALSE, message = FALSE}
est <- standardizedSolution(sem_output) %>%
  mutate(type = ifelse(op == "=~",
                       "loading",
                       ifelse(op == "~1",
                              "intercept",
                              ifelse(op == "~",
                                     "regression",
                                     ifelse(lhs == rhs,
                                            "variance",
                                            "covariance")))),
         estimate = sprintf("%.3f %s", `est.std`, gtools::stars.pval(pvalue))) %>%
  mutate(link = ifelse(type %in% c("loading", "covariance", "regression"),
                       sprintf("%s %s %s", lhs, op, rhs),
                       lhs)) %>%
  dplyr::select(type, link, estimate, se) %>%
  mutate(type = factor(as.factor(type),
                       levels = c("loading", "covariance", "regression",
                                  "variance"),
                       ordered = TRUE)) %>%
  arrange(type)
est[, -1] %>%
  kable(booktabs = TRUE,
        caption = "Standardized coefficient estimates and standard errors for the SEM.",
        col.names = c("", "Estimate", "SE"),
        digits = 3,
        longtable = TRUE) %>%
  kableExtra::kable_styling(font_size = 9) %>%
  kableExtra::group_rows(start_row = which(est$type == "loading")[1],
                         end_row = max(which(est$type == "loading")),
                         "Loadings") %>%
  kableExtra::group_rows(start_row = which(est$type == "variance")[1],
                         end_row = max(which(est$type == "variance")),
                         "Variance") %>%
  kableExtra::group_rows(start_row = which(est$type == "covariance")[1],
                         end_row = max(which(est$type == "covariance")),
                         "Covariance") %>%
  kableExtra::group_rows(start_row = which(est$type == "regression")[1],
                         end_row = max(which(est$type == "regression")),
                         "Regression")  %>%
  kable_styling(latex_options = c("repeat_header"), font_size = 9) %>%
  kableExtra::add_footnote(label = "* p <.05, ** p <.01, *** p <.001")
#which(t$type == "covariance")
#which(t$type == "variance")
```



\clearpage
# Bibliography
